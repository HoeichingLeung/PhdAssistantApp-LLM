{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70fde7c0-ecc0-4eb7-953f-e7ecd89b09c1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T21:20:39.498354Z",
     "iopub.status.busy": "2024-08-23T21:20:39.498171Z",
     "iopub.status.idle": "2024-08-23T21:20:39.501138Z",
     "shell.execute_reply": "2024-08-23T21:20:39.500531Z",
     "shell.execute_reply.started": "2024-08-23T21:20:39.498333Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    " #!pip install BCEmbedding==0.1.1\n",
    "# 安装 streamlit\n",
    " #! pip install streamlit==1.24.0\n",
    " #!pip install langchain\n",
    " #!pip install -U langchain-community\n",
    "# ! pip install modelscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c6c91d-e353-45e2-8279-4cb205a900d9",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T21:20:39.502563Z",
     "iopub.status.busy": "2024-08-23T21:20:39.502313Z",
     "iopub.status.idle": "2024-08-23T21:20:40.984953Z",
     "shell.execute_reply": "2024-08-23T21:20:40.984420Z",
     "shell.execute_reply.started": "2024-08-23T21:20:39.502544Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM\n",
    "import BCEmbedding  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188eb838-007e-4b82-a5dd-fdce51ab566e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T21:20:40.985986Z",
     "iopub.status.busy": "2024-08-23T21:20:40.985744Z",
     "iopub.status.idle": "2024-08-23T21:20:40.992087Z",
     "shell.execute_reply": "2024-08-23T21:20:40.991602Z",
     "shell.execute_reply.started": "2024-08-23T21:20:40.985966Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#用新模型的向量模型类\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class EmbeddingModel:\n",
    "    def __init__(self, model_name: str, device: str = 'cuda'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "    \n",
    "    def get_embeddings(self, sentences: List[str], batch_size: int = 8) -> np.ndarray:  \n",
    "        all_embeddings = []  \n",
    "        for i in range(0, len(sentences), batch_size):  \n",
    "            batch = sentences[i:i + batch_size]  \n",
    "            #print(batch)\n",
    "            inputs = self.tokenizer(batch, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")  \n",
    "            #print(inputs)\n",
    "            inputs_on_device = {k: v.to(self.device) for k, v in inputs.items()}  \n",
    "            with torch.no_grad():  \n",
    "                outputs = self.model(**inputs_on_device, return_dict=True)  \n",
    "            embeddings = outputs.last_hidden_state[:, 0]  \n",
    "            embeddings = embeddings / embeddings.norm(dim=1, keepdim=True)  \n",
    "            all_embeddings.append(embeddings.cpu().numpy())  \n",
    "        return np.vstack(all_embeddings)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4850e61-9d10-4551-9d4c-813b9ad3cfd4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T21:20:40.992897Z",
     "iopub.status.busy": "2024-08-23T21:20:40.992721Z",
     "iopub.status.idle": "2024-08-23T21:20:41.022937Z",
     "shell.execute_reply": "2024-08-23T21:20:41.022485Z",
     "shell.execute_reply.started": "2024-08-23T21:20:40.992878Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义向量库索引类\n",
    "class VectorStoreIndex:\n",
    "    \"\"\"\n",
    "    class for VectorStoreIndex\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, doecment_path: str, embed_model: EmbeddingModel) -> None:\n",
    "        self.documents = []\n",
    "        for line in open(doecment_path, 'r', encoding='utf-8'):\n",
    "            line = line.strip()\n",
    "            self.documents.append(line)\n",
    "\n",
    "        self.embed_model = embed_model\n",
    "        self.vectors = self.embed_model.get_embeddings(self.documents)\n",
    "\n",
    "        print(f'Loading {len(self.documents)} documents for {doecment_path}.')\n",
    "\n",
    "    def get_similarity(self, vector1: List[float], vector2: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        calculate cosine similarity between two vectors\n",
    "        \"\"\"\n",
    "        dot_product = np.dot(vector1, vector2)\n",
    "        magnitude = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
    "        if not magnitude:\n",
    "            return 0\n",
    "        return dot_product / magnitude\n",
    "\n",
    "    def query(self, question: str, k: int = 5) -> List[str]:\n",
    "        question_vector = self.embed_model.get_embeddings([question])[0]\n",
    "        result = np.array([self.get_similarity(question_vector, vector) for vector in self.vectors])\n",
    "        return np.array(self.documents)[result.argsort()[-k:][::-1]].tolist()\n",
    "    '''\n",
    "    def web_search(self, search_list):\n",
    "        os.environ[\"SERPER_API_KEY\"] = \"88a8892a02409063f02a3bb97ac08b36fb213ae7\"\n",
    "        search = GoogleSerperAPIWrapper()\n",
    "        search_result = ''\n",
    "        for prof_name in search_list:\n",
    "            search_item = prof_name + \"research interest\"\n",
    "            search_result+= str(search.run(search_item)) + '\\n'\n",
    "            \n",
    "        return search_result\n",
    "            # results = search.results(search_item)\n",
    "            # pprint.pp(results)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f768e1c4-cd27-4287-bd0f-19954e2434a9",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T21:20:41.023889Z",
     "iopub.status.busy": "2024-08-23T21:20:41.023573Z",
     "iopub.status.idle": "2024-08-23T21:20:54.996057Z",
     "shell.execute_reply": "2024-08-23T21:20:54.995473Z",
     "shell.execute_reply.started": "2024-08-23T21:20:41.023870Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Create embedding model...\n"
     ]
    }
   ],
   "source": [
    "print(\"> Create embedding model...\")\n",
    "embed_model = EmbeddingModel('BCEmbeddingmodel')\n",
    "# embed_model.get_embeddings(sentences)\n",
    "# # init embedding model\n",
    "# model = EmbeddingModel(model_name_or_path=\"AI-ModelScope/BCEmbeddingmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b278205a-cf45-4b34-a38e-db48a9a49f7f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T21:20:54.997145Z",
     "iopub.status.busy": "2024-08-23T21:20:54.996835Z",
     "iopub.status.idle": "2024-08-23T21:20:56.009533Z",
     "shell.execute_reply": "2024-08-23T21:20:56.008927Z",
     "shell.execute_reply.started": "2024-08-23T21:20:54.997122Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Create index...\n",
      "Loading 10 documents for ./test.txt.\n",
      "(10, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"> Create index...\")\n",
    "doecment_path = './test.txt'\n",
    "index = VectorStoreIndex(doecment_path, embed_model)\n",
    "\n",
    "#查看向量库的shape\n",
    "_vector = np.array(index.vectors)\n",
    "print(_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1616d89e-a3c0-4d67-b5ae-3a4523fcbcbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-23T21:20:56.011757Z",
     "iopub.status.busy": "2024-08-23T21:20:56.011285Z",
     "iopub.status.idle": "2024-08-23T21:20:56.218110Z",
     "shell.execute_reply": "2024-08-23T21:20:56.217562Z",
     "shell.execute_reply.started": "2024-08-23T21:20:56.011725Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712f36f2-73fb-44ff-9050-e8e89e15ae2f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T21:20:56.219116Z",
     "iopub.status.busy": "2024-08-23T21:20:56.218830Z",
     "iopub.status.idle": "2024-08-23T21:20:56.246692Z",
     "shell.execute_reply": "2024-08-23T21:20:56.246178Z",
     "shell.execute_reply.started": "2024-08-23T21:20:56.219093Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Question: Recommend professors in the field of Interdisciplinary Areas\n",
      "> Context: ['Dan Halperin specializes in the area(s) of Interdisciplinary Areas ,Theory and is interested in \\xa0Computer graphics,Comp. bio & bioinformatics,Robotics,Algorithms & complexity. They are part of the Tel Aviv University department, have a homepage at http://acg.cs.tau.ac.il/danhalperin, their scholar ID is NOSCHOLARPAGE, and the university holds a rank of 32.', 'Donald P. Greenberg specializes in the area(s) of Interdisciplinary Areas ,System and is interested in \\xa0Computer graphics,Design automation. They are part of the Cornell University department, have a homepage at http://aap.cornell.edu/people/donald-greenberg, their scholar ID is NOSCHOLARPAGE, and the university holds a rank of 8.', 'Alexander C. Berg specializes in the area(s) of AI,Interdisciplinary Areas ,System and is interested in \\xa0Natural language processing,Artificial intelligence,Computer vision,Machine learning,Robotics,Databases,Design automation,Embedded & real-time systems\\xa0. They are part of the Univ. of California - Irvine department, have a homepage at http://acberg.com, their scholar ID is jjEht8wAAAAJ, and the university holds a rank of 36.', 'Abhinav Shrivastava specializes in the area(s) of AI,Interdisciplinary Areas  and is interested in Artificial intelligence,Computer vision,Machine learning,\\xa0Computer graphics,Robotics. They are part of the University of Maryland - College Park department, have a homepage at http://abhinavsh.info, their scholar ID is mIF9BowAAAAJ, and the university holds a rank of 13.', 'Abe Davis specializes in the area(s) of AI,Interdisciplinary Areas  and is interested in Computer vision,\\xa0Computer graphics,Human-computer interaction. They are part of the Cornell University department, have a homepage at http://abedavis.com, their scholar ID is Gp8ghkAAAAJ, and the university holds a rank of 8.']\n"
     ]
    }
   ],
   "source": [
    "question = 'Recommend professors in the field of Interdisciplinary Areas'\n",
    "print('> Question:', question)\n",
    "\n",
    "context = index.query(question)\n",
    "print('> Context:', context)\n",
    "\n",
    "#context_web = index.web_search(context)\n",
    "#print('> Context_web:', context_web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bac24607-b9c7-4cda-b3c5-e3bf0a305a31",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T21:20:56.247705Z",
     "iopub.status.busy": "2024-08-23T21:20:56.247435Z",
     "iopub.status.idle": "2024-08-23T21:20:56.264144Z",
     "shell.execute_reply": "2024-08-23T21:20:56.263682Z",
     "shell.execute_reply.started": "2024-08-23T21:20:56.247685Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 下载Llama模型\n",
    "#from modelscope import snapshot_download\n",
    "#model_dir = snapshot_download('LLM-Research/Meta-Llama-3-8B-Instruct', cache_dir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17df5b9c-c723-49a6-8336-38403ff27d67",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T21:20:56.265042Z",
     "iopub.status.busy": "2024-08-23T21:20:56.264788Z",
     "iopub.status.idle": "2024-08-23T21:20:56.314991Z",
     "shell.execute_reply": "2024-08-23T21:20:56.314503Z",
     "shell.execute_reply.started": "2024-08-23T21:20:56.265023Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义大语言模型类  \n",
    "class LLM:  \n",
    "    \"\"\"  \n",
    "    class for Meta Llama 3 LLM  \n",
    "    \"\"\"  \n",
    "\n",
    "    def __init__(self, model_path: str) -> None:  \n",
    "        print(\"Creat tokenizer...\")\n",
    "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(model_path)  \n",
    "        \n",
    "        print(\"Creating model...\")  \n",
    "        self.model = transformers.AutoModelForCausalLM.from_pretrained(  \n",
    "            model_path,  \n",
    "            torch_dtype=torch.bfloat16  \n",
    "        ).cuda()  \n",
    "\n",
    "        print(f'Loading Llama 3 model from {model_path}.')  \n",
    "\n",
    "    def generate(self, question: str, context: list):  \n",
    "        if context:  \n",
    "            prompt = f'Background:{context}\\n Question: {question}\\n Please use the whole background to answer my question.'  \n",
    "        else:  \n",
    "            prompt = question  \n",
    "\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].cuda()  \n",
    "        outputs = self.model.generate(  \n",
    "            inputs,  \n",
    "            do_sample=True,  \n",
    "            max_new_tokens=256,  \n",
    "            temperature=0.6,  \n",
    "            top_p=0.9  \n",
    "        )  \n",
    "        output = self.tokenizer.decode(outputs[0], skip_special_tokens=True)  \n",
    "\n",
    "        print(output.strip())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc0659-14cf-4622-b1bb-461a151d601a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-23T21:20:56.315757Z",
     "iopub.status.busy": "2024-08-23T21:20:56.315587Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Create Llama3 LLM...\n",
      "Creat tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f268efdeb98a474fa043079d2780a3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers  \n",
    "import torch  \n",
    "print(\"> Create Llama3 LLM...\")\n",
    "model_path = './LLM-Research/Meta-Llama-3-8B-Instruct'\n",
    "torch.cuda.empty_cache()\n",
    "llm = LLM(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263569f8-6dad-4054-8d75-f6e689a1fcaa",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 生成回答\n",
    "torch.cuda.empty_cache()\n",
    "#print('> Without RAG:')\n",
    "#llm.generate(question, [])\n",
    "\n",
    "print('> With RAG:')\n",
    "llm.generate(question, context)#, context_web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a89fe3-0fe8-4a40-b82c-b3e953be456d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
